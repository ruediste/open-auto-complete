{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "tokenizer=AutoTokenizer.from_pretrained('data/bert')\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained('data/bert')\n",
    "tokenizer = AutoTokenizer.from_pretrained('data/bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58283d3384ab45dfb7b7d36c6070a82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['language', 'fileName', 'prefix', 'suffix', 'completion', 'expected', 'parameters'],\n",
       "    num_rows: 15472\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "ds=Dataset.from_json('data/data.json')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['language', 'fileName', 'prefix', 'suffix', 'completion', 'expected', 'parameters', 'chars'],\n",
       "    num_rows: 15472\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by characters, to make batching more efficient\n",
    "def count_chars(example):\n",
    "    return {'chars': len(example['prefix'])+len(example['suffix'])}\n",
    "dsSorted=ds.map(count_chars,batched=False, num_proc=8).sort('chars')\n",
    "dsSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3e72c1235a4fcfaf7f06a27163c1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15472 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "mask_id = tokenizer.convert_tokens_to_ids(\"<|mask|>\")\n",
    "pad_id = tokenizer.convert_tokens_to_ids(\"<|pad|>\")\n",
    "\n",
    "def padToLength(list,length, padding):\n",
    "    result=list[:length]\n",
    "    return result+[padding]*(length-len(result));\n",
    "\n",
    "languageIds={\n",
    "    'cs': 0,\n",
    "    'ts': 1,\n",
    "    'css': 2,\n",
    "};\n",
    "\n",
    "def generate_response(examples):\n",
    "    # Tokenize all prefixes and suffixes together\n",
    "    prefix_ids = tokenizer(examples[\"prefix\"], add_special_tokens=False,split_special_tokens=True)[\"input_ids\"]\n",
    "    suffix_ids = tokenizer(examples[\"suffix\"], add_special_tokens=False,split_special_tokens=True)[\"input_ids\"]\n",
    "\n",
    "\n",
    "    # Combine the IDs for each example in the batch\n",
    "    prompt_ids = [\n",
    "       prefix + [mask_id]*5 + suffix\n",
    "       for prefix, suffix in zip(prefix_ids, suffix_ids)\n",
    "    ]\n",
    "\n",
    "    attention_mask = [[1] * len(ids) for ids in prompt_ids]\n",
    "\n",
    "    # pad batch\n",
    "    max_length= 8*math.ceil(max([len(ids) for ids in prompt_ids])/8)\n",
    "    p_prompt_ids=[padToLength(ids,max_length, pad_id) for ids in prompt_ids]\n",
    "    p_attention_mask=[padToLength(ids,max_length, 0) for ids in attention_mask]\n",
    "    p_token_type = [[languageIds[lang]] * max_length for lang in examples[\"language\"]]\n",
    "\n",
    "    outputs = F.softmax(model(**{\n",
    "        \"input_ids\": torch.tensor(p_prompt_ids, dtype=torch.int64),\n",
    "        \"attention_mask\":torch.tensor(p_attention_mask, dtype=torch.int64),\n",
    "        'token_type_ids':torch.tensor(p_token_type, dtype=torch.int64)\n",
    "    }).logits,dim=-1).argmax(-1)\n",
    "    outputs = [out[len(prefix):len(prefix)+5] for out,prefix in zip(outputs,prefix_ids)]\n",
    "    response= [tokenizer.decode(ids, clean_up_tokenization_spaces=True, skip_special_tokens=True) for ids in outputs]\n",
    "    return {\n",
    "        'response': response, \n",
    "        'match': [r.startswith(exp) for r,exp in zip(response, examples['expected'])]\n",
    "    }\n",
    "\n",
    "ds2=dsSorted.map(generate_response, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX: 1) / Time.Hour.ToBase(1));\n",
      "\n",
      "    public double BaseUnitValue { get; }\n",
      "\n",
      "    public VolumeFlow(double baseUnitValue)\n",
      "    {\n",
      "        this.BaseUnitValue = baseUnitValue;\n",
      "    }\n",
      "\n",
      "    public static VolumeFlow \n",
      "EXPECTED: FromBaseUn\n",
      "RESPOSE: Get get\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: ForMassFlowAndTemperature(ocl.Id, ocl.DisplayName(args.NumberAssignment), calculation, null, state => massFlow * (ocl.GetDirection() == Direction.Out ? 1 : -1), state => temperature.Value, state => ma\n",
      "EXPECTED: ssFractions, \n",
      "RESPOSE: x..\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: eInfo };\n",
      "\n",
      "        // add starting element\n",
      "        if (endpoint.Port != null)\n",
      "        {\n",
      "            this.AddMainFlowElement(endpoint.Port.Element, endpoint.Port, flow);\n",
      "        }\n",
      "\n",
      "        if (endpoint.\n",
      "EXPECTED: Ocl != \n",
      "RESPOSE: start.\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: is.SecondaryInPorts.Concat(this.SecondaryOutPorts))\n",
      "        {\n",
      "            port.Delete();\n",
      "        }\n",
      "\n",
      "        this.SecondaryInPorts.Clear();\n",
      "        this.SecondaryOutPorts.Clear();\n",
      "        this.Initiali\n",
      "EXPECTED: zePorts();\n",
      "RESPOSE: ze();();();\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: er(connectionInfo, new ProjectValueIdentifier(projectId), new RepositoryValueViewMapperValueHandle(projectHandle), builder =>\n",
      "        {\n",
      "            builder.Register(c => projectHandle.Value).AsSelf();\n",
      "EXPECTED: \n",
      "            builder.\n",
      "RESPOSE: \n",
      "            builder.\n",
      "MATCH: True\n",
      "\n",
      "PREFIX: A0zn4UaQ4GFig4isDDA+wUGWJgkMBTLBTPxxAATZu6GWBFwZkHOTNxhnjHucmbeaKhm7IXMWPVumWfMiwy8YyZBMKNw4QYInLm86caGGZrPmXtnRuEO8wInyMzZU5gxMwqzBOgCPoUZBggzA2RmQJhRcY9ZZQbzggplBkFrAWFG4BVzuEE2CTTJDSLckAMA8qwTXLiR+\n",
      "EXPECTED: yxA4YKZRwb4GZRWxAvmyDoj0KxDACdNCDzrGrrhWUfNFRheMRN5bghY4EEnaVcjBQdwxbwZ3e+\n",
      "RESPOSE: AwHH\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: e == ConnectionType.SecondaryFlow;\n",
      "\n",
      "    public OperationConditionLocation Duplicate(Frame frame, DuplicationContext context)\n",
      "    {\n",
      "        var duplicate = new OperationConditionLocation\n",
      "        {\n",
      "    \n",
      "EXPECTED:         Graph = \n",
      "RESPOSE:         return new = =\n",
      "MATCH: False\n",
      "\n",
      "PREFIX:  PageSize DinFormat { get; init; } = PageSize.A4;\n",
      "\n",
      "    public PdfAStandard ArchiveStandard { get; init; } = PdfAStandard.A1B;\n",
      "\n",
      "    public bool IsLandscapeMode { get; init; }\n",
      "\n",
      "    public string Font { \n",
      "EXPECTED: get; \n",
      "RESPOSE: get;\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: ame = calculation.CalculationGroup.Frame;\n",
      "\n",
      "        calculation.Connections\n",
      "            .Where(c => c.ConnectionType == ConnectionType.MainFlow)\n",
      "            .ForEach(c =>\n",
      "            {\n",
      "                \n",
      "EXPECTED: var \n",
      "RESPOSE: re c\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: c SimulationMainFlowPort? Target => this.target;\n",
      "\n",
      "    public static SimulationMainFlowConnection Connect(IdSource idSource, ConnectionType type, SimulationMainFlowPort source, SimulationMainFlowPort? \n",
      "EXPECTED: target)\n",
      "  \n",
      "RESPOSE: =)\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: ons;\n",
      "\n",
      "[MapperConfig(Category = ViewMapperCategory.None)]\n",
      "public class CalculationStatusMapper : ViewMapper<CalculationStatusMapper.CalculationStatusView>\n",
      "{\n",
      "    public required SimulationAppController \n",
      "EXPECTED: simulationAppController;\n",
      "    \n",
      "RESPOSE: : get;\n",
      "MATCH: False\n",
      "\n",
      "PREFIX:  static string GetSvg(int flowNr, StageGroupElement.Direction direction)\n",
      "    {\n",
      "        return $\"\"\"\n",
      "            <rect\n",
      "               x=\"0\"\n",
      "               y=\"0\"\n",
      "               width=\"44\"\n",
      "               \n",
      "EXPECTED: height=\"\n",
      "RESPOSE:   \"=\"\"\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: using Nito.Asy\n",
      "EXPECTED: ncEx;\n",
      "\n",
      "\n",
      "RESPOSE: ncc\n",
      "using\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: ompare signatures. Avoid timing attacks by comparing all bytes\n",
      "        if (calculatedSignature.Length != providedSignature.Length)\n",
      "        {\n",
      "            return false;\n",
      "        }\n",
      "\n",
      "        int bitMismatc\n",
      "EXPECTED: h = \n",
      "RESPOSE: h(\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: th.PI, 2) / 32 * (Math.Pow(impellerDiameter, 2) - Math.Pow(labyrinthDiameter, 2))));\n",
      "        }\n",
      "\n",
      "        return this.LeakagePressureAfterImpeller.Get(state) switch\n",
      "        {\n",
      "            Configurations.\n",
      "EXPECTED: Model.\n",
      "RESPOSE: PP\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: mperature\"></param>\n",
      "    /// <returns></returns>\n",
      "    private double LeeKeslerSpecificVolume(double pressure, double temperature)\n",
      "    {\n",
      "        var compressibility = this.LeeKeslerCompressibility(pressu\n",
      "EXPECTED: re, \n",
      "RESPOSE: re);\n",
      "      \n",
      "MATCH: False\n",
      "\n",
      "PREFIX:     this.semaphore.Dispose();\n",
      "    }\n",
      "\n",
      "    private record SynchronizationProcess(CancellationTokenSource Source) : IDisposable\n",
      "    {\n",
      "        public void Dispose()\n",
      "        {\n",
      "            this.Source.Cance\n",
      "EXPECTED: l();\n",
      "            \n",
      "RESPOSE: l();();(); }\n",
      "MATCH: False\n",
      "\n",
      "PREFIX: EditorView> Map()\n",
      "    {\n",
      "        MapContext ctx = new();\n",
      "        var result = new SchemaEditorView\n",
      "        {\n",
      "            NextId = this.project.Graph.NextId,\n",
      "            SelectedObjectId = this.project.\n",
      "EXPECTED: SelectedSchemaObjectId,\n",
      "            \n",
      "RESPOSE: Get,,,   \n",
      "MATCH: False\n",
      "\n",
      "PREFIX: opy, logger),\n",
      "                    _ => throw new ArgumentException(\"Interpolation option can only be 1: for given pressure and temperature, 2: for given pressure and enthalpy or 3: for given enthalpy \n",
      "EXPECTED: and \n",
      "RESPOSE: th m\n",
      "MATCH: False\n",
      "\n",
      "PREFIX:  entry.ViewMapper.GetType().GetMethod(invocation.Name);\n",
      "\n",
      "        if (methodInfo == null)\n",
      "        {\n",
      "            throw new Exception(\"Method \" + invocation.Name + \" not found in \" + entry.ViewMapper.Get\n",
      "EXPECTED: Type().\n",
      "RESPOSE: M(\n",
      "MATCH: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "rows=[]\n",
    "for example in ds2.shuffle().take(20):\n",
    "    print('PREFIX: '+example['prefix'])\n",
    "    print('EXPECTED: '+example['expected'])\n",
    "    print('RESPOSE: '+example['response'])\n",
    "    print('MATCH: '+str(example['match']))\n",
    "    print()\n",
    "    row=example['parameters'].copy()\n",
    "    row['match']=example['match']\n",
    "    rows.append(row)\n",
    "# print(rows)\n",
    "with open('data/results2.json', 'w') as file:\n",
    "    json.dump(rows, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
